{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4useoiEBjV6",
        "outputId": "a92fba94-90a5-4ef5-9f52-f5c873f55b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.14.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=userdata.get(\"OPENROUTER_API_KEY\"),\n",
        "    base_url=\"https://openrouter.ai/api/v1\",  # OpenRouter OpenAI-compatible base URL\n",
        ")"
      ],
      "metadata": {
        "id": "h9roHMwhFs6u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make posts from doc\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "import requests\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "# retrieve data from notion\n",
        "\n",
        "NOTION_TOKEN = userdata.get(\"NOTION_API\")\n",
        "PAGE_ID = \"2ee0a735274f80b6a961ee81eed44b06\"\n",
        "NOTION_VERSION = \"2025-09-03\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {NOTION_TOKEN}\",\n",
        "    \"Notion-Version\": NOTION_VERSION,\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "def notion_get(url: str, params: Dict[str, Any] | None = None) -> Dict[str, Any]:\n",
        "    r = requests.get(url, headers=headers, params=params)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def list_block_children(block_id: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Fetches all child blocks (paginated).\"\"\"\n",
        "    results = []\n",
        "    url = f\"https://api.notion.com/v1/blocks/{block_id}/children\"\n",
        "    cursor = None\n",
        "    while True:\n",
        "        params = {\"start_cursor\": cursor} if cursor else None\n",
        "        data = notion_get(url, params=params)\n",
        "        results.extend(data.get(\"results\", []))\n",
        "        if not data.get(\"has_more\"):\n",
        "            break\n",
        "        cursor = data.get(\"next_cursor\")\n",
        "    return results\n",
        "\n",
        "def rich_text_to_plain(rt: List[Dict[str, Any]]) -> str:\n",
        "    return \"\".join(x.get(\"plain_text\", \"\") for x in (rt or []))\n",
        "\n",
        "def block_to_text(block: Dict[str, Any]) -> str:\n",
        "    t = block[\"type\"]\n",
        "    if t in (\"paragraph\", \"heading_1\", \"heading_2\", \"heading_3\", \"bulleted_list_item\", \"numbered_list_item\", \"to_do\", \"quote\", \"callout\"):\n",
        "        obj = block[t]\n",
        "        return rich_text_to_plain(obj.get(\"rich_text\", []))\n",
        "    if t == \"code\":\n",
        "        obj = block[t]\n",
        "        lang = obj.get(\"language\", \"\")\n",
        "        code = rich_text_to_plain(obj.get(\"rich_text\", []))\n",
        "        return f\"```{lang}\\n{code}\\n```\"\n",
        "    if t == \"divider\":\n",
        "        return \"---\"\n",
        "    if t == \"image\":\n",
        "        return block[\"image\"].get(\"caption\", [{}])[0].get(\"plain_text\", \"\") or \"[image]\"\n",
        "    return f\"[{t}]\"\n",
        "def normalize(text: str)-> str:\n",
        "    return unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "def walk_blocks(block_id: str, indent: int = 0) -> List[str]:\n",
        "    lines = []\n",
        "    children = list_block_children(block_id)\n",
        "    for b in children:\n",
        "        prefix = \"  \" * indent\n",
        "        text = block_to_text(b)\n",
        "        if text.strip():\n",
        "            lines.append(prefix + text)\n",
        "        if b.get(\"has_children\"):\n",
        "            lines.extend(walk_blocks(b[\"id\"], indent=indent + 1))\n",
        "    return normalize(\"\\n\".join(lines))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lines = walk_blocks(PAGE_ID)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mzhluqXAEq7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc30698e-f398-4340-eb28-1b4e7fcb5c7f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A company that gives oral exams based on material uploaded. \n",
            "Description:\n",
            "A platform that automatically generates and administers oral examinations based on user-uploaded materials. Educators, institu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date"
      ],
      "metadata": {
        "id": "JnmofZnzlgGQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make posts from llm\n",
        "from datetime import date\n",
        "from pydantic import BaseModel, Field, ValidationError, field_validator, model_validator\n",
        "\n",
        "class Status(BaseModel):\n",
        "    status: str = Field(min_length=3, description=\"The post text to publish on Mastodon (<= 100 words).\")\n",
        "    date_posted: date = Field(description=\"Target date for posting (YYYY-MM-DD).\")\n",
        "    content: str = Field(description=\"Short internal rationale or angle for the post (not posted).\")\n",
        "\n",
        "class StatusList(BaseModel):\n",
        "    posts: List[Status] = Field(min_length=1, description=\"List of generated posts.\")\n",
        "\n",
        "\n",
        "num_posts = 5\n",
        "instructions = f\"make {num_posts} post markting my company under 100 words using the following information: \" + lines\n",
        "posts = client.responses.parse(\n",
        "      model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
        "      input= instructions,\n",
        "      text_format=StatusList,\n",
        "  )\n",
        "# posts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcydfvIuau-n",
        "outputId": "6bb48bd2-bb6d-4548-e827-f246cbac3863"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParsedResponse[StatusList](id='gen-1768966354-hcIXByFWNGW3kf0SM2aA', created_at=1768966354.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='nvidia/nemotron-3-nano-30b-a3b:free', object='response', output=[ResponseReasoningItem(id='rs_tmp_ar49c92fovw', summary=[], type='reasoning', content=[Content(text=\"We need to produce 5 promotional posts under 100 words each, based on given info. Provide 5 separate posts, each <100 words. Should be marketing style. We'll deliver concise posts.\\n\\nWe'll count roughly. Provide them as separate bullet points or numbered. Ensure each is within 100 words.\\n\\nLet's craft.\\n\", type='reasoning_text')], encrypted_content=None, status=None), ParsedResponseOutputMessage[StatusList](id='msg_tmp_sz9l2xm508', content=[ParsedResponseOutputText[StatusList](annotations=[], text='{\\n \"posts\": [\\n   {\\n     \"status\": \"Ready\",\\n     \"date_posted\": \"2025-11-02\",\\n     \"content\": \"ðŸš€ Transform exams with AIâ€‘powered oral assessments! Our platform ingests PDFs, slides, notes, and more, then crafts interactive spoken quizzes that test real understandingâ€”not memorization. Ready to scale authentic assessment? Learn how educators, corporates, and certification bodies are boosting learning outcomes. #OralExam #EdTech #AssessmentInnovation\"\\n   },\\n   {\\n     \"status\": \"Ready\",\\n     \"date_posted\": \"2025-11-04\",\\n     \"content\": \"ðŸ“š Upload any source material and watch the system autoâ€‘generate structured oral exams. From lecture PDFs to training manuals, the AI identifies key concepts, difficulty levels, and learning objectives. The result? Liveâ€‘style questioning that evaluates reasoning, articulation, and depth. Elevate assessment integrity while saving time. #AIInEducation #DeepLearning #ScaleAssessments\"\\n   },\\n   {\\n     \"status\": \"Ready\",\\n     \"date_posted\": \"2025-11-06\",\\n     \"content\": \"ðŸ’¡ Say goodbye to roteâ€‘recall exams! Our solution delivers scenarioâ€‘based, conversational assessments marked against precise criteriaâ€”clarity, concept mastery, and knowledge gaps. Whether for language learning, professional certification, or corporate onboarding, get instant, actionable feedback. Empower students and professionals to explain and defend ideas in real time. #AssessmentDesign #LearningOutcomes #EdTechLaunch\"\\n   },\\n   {\\n     \"status\": \"Ready\",\\n     \"date_posted\": \"2025-11-08\",\\n     \"content\": \"ðŸŒ From university classrooms to global corporations, our platform makes oral exams accessible and scalable. Conduct asynchronous video exams or synchronous live sessions across disciplines and time zones. Reduce plagiarism, encourage critical thinking, and verify competency with intelligent evaluation. Join the future of fair, authentic assessment. #EdTech #CorporateTraining #FutureOfLearning\"\\n   },\\n   {\\n     \"status\": \"Ready\",\\n     \"date_posted\": \"2025-11-10\",\\n     \"content\": \"ðŸ† Experience the only solution that mimics the rigor of traditional oral exams while leveraging automation for large cohorts. Customizable parametersâ€”difficulty, length, question styleâ€”ensure alignment with any curriculum or industry standard. Ready to deploy? Request a demo and see how AI can transform your assessment workflow. #AssessmentAutomation #OralExams #EdTechDemo\"\\n   }\\n ]\\n}', type='output_text', logprobs=[], parsed=StatusList(posts=[Status(status='Ready', date_posted=datetime.date(2025, 11, 2), content='ðŸš€ Transform exams with AIâ€‘powered oral assessments! Our platform ingests PDFs, slides, notes, and more, then crafts interactive spoken quizzes that test real understandingâ€”not memorization. Ready to scale authentic assessment? Learn how educators, corporates, and certification bodies are boosting learning outcomes. #OralExam #EdTech #AssessmentInnovation'), Status(status='Ready', date_posted=datetime.date(2025, 11, 4), content='ðŸ“š Upload any source material and watch the system autoâ€‘generate structured oral exams. From lecture PDFs to training manuals, the AI identifies key concepts, difficulty levels, and learning objectives. The result? Liveâ€‘style questioning that evaluates reasoning, articulation, and depth. Elevate assessment integrity while saving time. #AIInEducation #DeepLearning #ScaleAssessments'), Status(status='Ready', date_posted=datetime.date(2025, 11, 6), content='ðŸ’¡ Say goodbye to roteâ€‘recall exams! Our solution delivers scenarioâ€‘based, conversational assessments marked against precise criteriaâ€”clarity, concept mastery, and knowledge gaps. Whether for language learning, professional certification, or corporate onboarding, get instant, actionable feedback. Empower students and professionals to explain and defend ideas in real time. #AssessmentDesign #LearningOutcomes #EdTechLaunch'), Status(status='Ready', date_posted=datetime.date(2025, 11, 8), content='ðŸŒ From university classrooms to global corporations, our platform makes oral exams accessible and scalable. Conduct asynchronous video exams or synchronous live sessions across disciplines and time zones. Reduce plagiarism, encourage critical thinking, and verify competency with intelligent evaluation. Join the future of fair, authentic assessment. #EdTech #CorporateTraining #FutureOfLearning'), Status(status='Ready', date_posted=datetime.date(2025, 11, 10), content='ðŸ† Experience the only solution that mimics the rigor of traditional oral exams while leveraging automation for large cohorts. Customizable parametersâ€”difficulty, length, question styleâ€”ensure alignment with any curriculum or industry standard. Ready to deploy? Request a demo and see how AI can transform your assessment workflow. #AssessmentAutomation #OralExams #EdTechDemo')]))], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=None, safety_identifier=None, service_tier='auto', status='completed', text=ResponseTextConfig(format=ResponseFormatTextJSONSchemaConfig(name='StatusList', schema_={'$defs': {'Status': {'properties': {'status': {'description': 'The post text to publish on Mastodon (<= 100 words).', 'minLength': 3, 'title': 'Status', 'type': 'string'}, 'date_posted': {'description': 'Target date for posting (YYYY-MM-DD).', 'format': 'date', 'title': 'Date Posted', 'type': 'string'}, 'content': {'description': 'Short internal rationale or angle for the post (not posted).', 'title': 'Content', 'type': 'string'}}, 'required': ['status', 'date_posted', 'content'], 'title': 'Status', 'type': 'object', 'additionalProperties': False}}, 'properties': {'posts': {'description': 'List of generated posts.', 'items': {'$ref': '#/$defs/Status'}, 'minItems': 1, 'title': 'Posts', 'type': 'array'}}, 'required': ['posts'], 'title': 'StatusList', 'type': 'object', 'additionalProperties': False}, type='json_schema', description=None, strict=True), verbosity=None), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=2113, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=649, output_tokens_details=OutputTokensDetails(reasoning_tokens=80), total_tokens=2762, cost=0, is_byok=False, cost_details={'upstream_inference_cost': None, 'upstream_inference_input_cost': 0, 'upstream_inference_output_cost': 0}), user=None, completed_at=1768966357, output_text='', presence_penalty=0, frequency_penalty=0, store=False)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "parsed = (\n",
        "    getattr(posts, \"output_parsed\", None)\n",
        "    or getattr(posts, \"parsed\", None)\n",
        "    or posts\n",
        ")\n",
        "\n",
        "hashtag = \" #marketing #AIGenerated\"  # note leading space\n",
        "\n",
        "MASTODON_INSTANCE = \"https://mastodon.social\"\n",
        "ACCESS_TOKEN = userdata.get(\"MASTODON_API\")\n",
        "url = f\"{MASTODON_INSTANCE}/api/v1/statuses\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
        "}\n",
        "\n",
        "def make_post():\n",
        "    for post in parsed.posts:\n",
        "        payload = {\n",
        "            \"status\": post.content + hashtag,  # FIXED\n",
        "            \"visibility\": \"unlisted\",\n",
        "        }\n",
        "\n",
        "        r = requests.post(url, data=payload, headers=headers)\n",
        "        r.raise_for_status()\n",
        "\n",
        "        print(\"Posted:\", r.json()[\"url\"])\n",
        "\n",
        "make_post()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYfzZP_pkVMT",
        "outputId": "38a3269e-4f60-471b-bf05-ff9c81b7c333"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posted: https://mastodon.social/@cesia/115931058068552336\n",
            "Posted: https://mastodon.social/@cesia/115931058110818092\n",
            "Posted: https://mastodon.social/@cesia/115931058152382544\n",
            "Posted: https://mastodon.social/@cesia/115931058212836028\n",
            "Posted: https://mastodon.social/@cesia/115931058280759310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "def html_to_text(html: str) -> str:\n",
        "    return BeautifulSoup(html or \"\", \"html.parser\").get_text(\" \", strip=True)\n",
        "\n",
        "def mastodon_search_statuses(instance: str, token: str, keyword: str, limit: int = 5):\n",
        "    \"\"\"\n",
        "    Uses Mastodon v2 search endpoint to find statuses.\n",
        "    Note: Some instances require auth and/or only return results within your instance / context.\n",
        "    \"\"\"\n",
        "    url = f\"{instance}/api/v2/search\"\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    params = {\n",
        "        \"q\": keyword,\n",
        "        \"type\": \"statuses\",\n",
        "        \"limit\": limit,\n",
        "        \"resolve\": True,  # attempt to resolve remote results (instance-dependent)\n",
        "    }\n",
        "    r = requests.get(url, headers=headers, params=params)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    return data.get(\"statuses\", [])\n",
        "class PostForReply(BaseModel):\n",
        "    id: str\n",
        "    url: Optional[str] = None\n",
        "    author_acct: str\n",
        "    text: str\n",
        "\n",
        "class ReplyDraft(BaseModel):\n",
        "    in_reply_to_id: str\n",
        "    reply_text: str = Field(min_length=1, description=\"Reply text WITHOUT the leading @handle (we add that).\")\n",
        "\n",
        "class ReplyBatch(BaseModel):\n",
        "    replies: List[ReplyDraft] = Field(min_length=1)\n",
        "\n",
        "\n",
        "KEYWORD = \"#Articulate\"\n",
        "\n",
        "MASTODON_INSTANCE = \"https://mastodon.social\"\n",
        "ACCESS_TOKEN = userdata.get(\"MASTODON_API\")  # or your token string\n",
        "\n",
        "raw_statuses = mastodon_search_statuses(MASTODON_INSTANCE, ACCESS_TOKEN, KEYWORD, limit=5)\n",
        "\n",
        "posts_for_llm: List[PostForReply] = []\n",
        "for s in raw_statuses[:5]:\n",
        "    posts_for_llm.append(\n",
        "        PostForReply(\n",
        "            id=s[\"id\"],\n",
        "            url=s.get(\"url\"),\n",
        "            author_acct=s[\"account\"][\"acct\"],\n",
        "            text=html_to_text(s.get(\"content\", \"\"))[:1200],  # keep prompt compact\n",
        "        )\n",
        "    )\n",
        "\n",
        "BUSINESS_BLURB = (\n",
        "    \"My company helps educators administer oral exams to students \"\n",
        ")\n",
        "\n",
        "instructions = f\"\"\"\n",
        "You are writing replies on Mastodon.\n",
        "\n",
        "Goal:\n",
        "- Write thoughtful, non-spammy replies to 5 recent posts related to: \"{KEYWORD}\"\n",
        "- Replies should be genuinely useful and context-aware.\n",
        "- Keep each reply <= 60 words.\n",
        "- Do NOT include links unless the original post asks for resources.\n",
        "- Avoid over-marketing; at most, a soft mention like \"I work on X\" if relevant.\n",
        "- Be polite and human.\n",
        "\n",
        "Business context:\n",
        "{BUSINESS_BLURB}\n",
        "\n",
        "Return JSON matching the schema ReplyBatch.\n",
        "Each ReplyDraft must reference the exact in_reply_to_id from the provided posts.\n",
        "\"\"\"\n",
        "\n",
        "# Provide the posts as data to ground the generation\n",
        "prompt_payload = {\n",
        "    \"instructions\": instructions,\n",
        "    \"posts\": [p.model_dump() for p in posts_for_llm],\n",
        "}\n",
        "\n",
        "response = client.responses.parse(\n",
        "    model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
        "    input=str(prompt_payload),\n",
        "    text_format=ReplyBatch,\n",
        ")\n",
        "\n",
        "parsed = getattr(response, \"output_parsed\", None) or getattr(response, \"parsed\", None) or response\n",
        "reply_batch: ReplyBatch = parsed\n",
        "reply_batch\n",
        "\n"
      ],
      "metadata": {
        "id": "a9vL-eDG_Q5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d60baa0-cf99-4279-c987-de52bb141726"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReplyBatch(replies=[ReplyDraft(in_reply_to_id='115930893404544962', reply_text='Great insights! Clear, concise speaking is key in any classroom. Our platform helps educators design oral exams that train students to articulate their ideas clearly, building confidence over time. Happy to discuss how we support that process!'), ReplyDraft(in_reply_to_id='115861572553958934', reply_text='Congrats on completing those modules! Storyline is powerful, and weâ€™ve seen educators use similar structured tools to assess verbal skills. Our solution lets you create and evaluate oral exams directly within your LMS, reducing the need for workâ€‘arounds. Let me know if youâ€™d like to explore integration ideas.'), ReplyDraft(in_reply_to_id='115721110562555815', reply_text='Exactlyâ€”simple, clear messaging builds trust, whether leading a team or guiding students. Our tools help educators craft precise oral instructions that students can confidently deliver. Itâ€™s rewarding to see clearer articulation translate into stronger learning outcomes. Would love to hear how you apply this in practice!'), ReplyDraft(in_reply_to_id='115609043795914986', reply_text='Love the linguistic roots! â€œArticulateâ€ evolving from jointâ€‘related meanings to describing clear speech is a neat parallel for educatorsâ€”connecting different concepts to convey ideas clearly. Our platform bridges gaps, helping teachers connect assessment with student articulation in meaningful ways.')])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def post_replies(instance: str, token: str, posts: List[PostForReply], batch: ReplyBatch, visibility: str = \"unlisted\"):\n",
        "    url = f\"{instance}/api/v1/statuses\"\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "\n",
        "    # Map id -> author acct\n",
        "    id_to_acct = {p.id: p.author_acct for p in posts}\n",
        "\n",
        "    posted_urls = []\n",
        "    for r in batch.replies:\n",
        "        acct = id_to_acct.get(r.in_reply_to_id)\n",
        "        if not acct:\n",
        "            continue\n",
        "\n",
        "        status_text = f\"@{acct} {r.reply_text}\".strip()\n",
        "\n",
        "        payload = {\n",
        "            \"status\": status_text,\n",
        "            \"in_reply_to_id\": r.in_reply_to_id,\n",
        "            \"visibility\": visibility,  # \"public\" | \"unlisted\" | \"private\" | \"direct\"\n",
        "        }\n",
        "\n",
        "        resp = requests.post(url, data=payload, headers=headers)\n",
        "        resp.raise_for_status()\n",
        "        posted_urls.append(resp.json().get(\"url\"))\n",
        "        print(\"Replied:\", posted_urls[-1])\n",
        "\n",
        "    return posted_urls\n",
        "\n",
        "posted = post_replies(MASTODON_INSTANCE, ACCESS_TOKEN, posts_for_llm, reply_batch, visibility=\"unlisted\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6nD_RCFvXdg",
        "outputId": "3e014078-83c0-46ae-f3ed-15e8392884ab"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replied: https://mastodon.social/@cesia/115931320458897718\n",
            "Replied: https://mastodon.social/@cesia/115931320478007595\n",
            "Replied: https://mastodon.social/@cesia/115931320537932796\n",
            "Replied: https://mastodon.social/@cesia/115931320592041289\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://mastodon.social/@cesia/115931320458897718',\n",
              " 'https://mastodon.social/@cesia/115931320478007595',\n",
              " 'https://mastodon.social/@cesia/115931320537932796',\n",
              " 'https://mastodon.social/@cesia/115931320592041289']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTRwF9TUxzRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}