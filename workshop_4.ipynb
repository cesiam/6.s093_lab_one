{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2IVlYPxikH7"
      },
      "source": [
        "# Workshop 4: RAG with Hybrid Search\n",
        "\n",
        "In this workshop, we'll build a **Retrieval-Augmented Generation (RAG)** system that:\n",
        "\n",
        "1. **Embeds** documents using local MiniLM-L6-v2 (no API calls)\n",
        "2. **Stores** embeddings in SQLite with FTS5 for keyword search\n",
        "3. **Retrieves** context using hybrid BM25 + semantic search\n",
        "4. **Generates** posts grounded in your knowledge base\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VBA_7omikH8"
      },
      "source": [
        "---\n",
        "## Part 1: Setup and Database Initialization\n",
        "\n",
        "We'll use SQLite with FTS5 (Full-Text Search 5) for efficient keyword search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z_UNzLw9ikH8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install required packages (run once)\n",
        "!pip install -q sqlite-vec fastembed numpy openai mastodon.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6w_2DF8rikH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5346d861-3c5b-4dd6-a674-753c2adaa436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard libraries loaded!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# We rely on Colab Secrets or manual input, so we don't need dotenv here.\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv(Path(\"../.env\"))\n",
        "\n",
        "print(\"Standard libraries loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-Mdhp_XdikH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47142334-28e7-4541-fef4-e45775ca3497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized at: tutorial_rag.db\n",
            "sqlite-vec extension loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import sqlite_vec\n",
        "\n",
        "# Initialize SQLite database with FTS5 and sqlite-vec support\n",
        "DATABASE_PATH = Path(\"tutorial_rag.db\")\n",
        "\n",
        "def init_database(db_path: Path) -> sqlite3.Connection:\n",
        "    \"\"\"Create database with embeddings table, FTS5 for BM25, and vec0 for vectors.\"\"\"\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    conn.row_factory = sqlite3.Row\n",
        "\n",
        "    # Load sqlite-vec extension\n",
        "    conn.enable_load_extension(True)\n",
        "    sqlite_vec.load(conn)\n",
        "    conn.enable_load_extension(False)\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Metadata table (stores content and metadata, linked to vectors by rowid)\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS embeddings_meta (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            source_type TEXT NOT NULL,\n",
        "            source_id TEXT,\n",
        "            content TEXT NOT NULL,\n",
        "            metadata TEXT,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    # Vector table using sqlite-vec (384 dimensions for MiniLM-L6-v2)\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE VIRTUAL TABLE IF NOT EXISTS vec_embeddings USING vec0(\n",
        "            embedding float[384] distance_metric=cosine\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    # FTS5 virtual table for BM25 keyword search\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE VIRTUAL TABLE IF NOT EXISTS embeddings_fts USING fts5(\n",
        "            content,\n",
        "            source_type,\n",
        "            source_id,\n",
        "            content='embeddings_meta',\n",
        "            content_rowid='id'\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    # Triggers to keep FTS5 in sync with embeddings_meta table\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TRIGGER IF NOT EXISTS embeddings_ai AFTER INSERT ON embeddings_meta BEGIN\n",
        "            INSERT INTO embeddings_fts(rowid, content, source_type, source_id)\n",
        "            VALUES (new.id, new.content, new.source_type, new.source_id);\n",
        "        END\n",
        "    \"\"\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TRIGGER IF NOT EXISTS embeddings_ad AFTER DELETE ON embeddings_meta BEGIN\n",
        "            INSERT INTO embeddings_fts(embeddings_fts, rowid, content, source_type, source_id)\n",
        "            VALUES ('delete', old.id, old.content, old.source_type, old.source_id);\n",
        "        END\n",
        "    \"\"\")\n",
        "\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Initialize the database\n",
        "db = init_database(DATABASE_PATH)\n",
        "print(f\"Database initialized at: {DATABASE_PATH}\")\n",
        "print(\"sqlite-vec extension loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK3p_E4zikH9"
      },
      "source": [
        "<cell_type>markdown</cell_type>### Understanding the Database Schema\n",
        "\n",
        "We use **two storage mechanisms** for different search types:\n",
        "\n",
        "1. **sqlite-vec (`vec0`)** - Native vector storage for cosine similarity search\n",
        "   - Stores 384-dimensional embeddings compactly\n",
        "   - MATCH queries use optimized ANN (Approximate Nearest Neighbor)\n",
        "   - Returns cosine **distance** (0 = identical, 2 = opposite)\n",
        "\n",
        "2. **FTS5** - Full-text search for BM25 keyword matching\n",
        "   - Indexes words for fast exact-term lookup\n",
        "   - BM25 scoring ranks by term frequency/document frequency\n",
        "   - Returns negative scores (more negative = better match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i8JKy2yikH9"
      },
      "source": [
        "### Part 2: Document Chunking\n",
        "\n",
        "Large documents should be split into smaller chunks for better retrieval. We chunk by `##` headers to maintain semantic coherence. But it can be different for every knowledge base"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any, List, Optional, Set\n",
        "import requests\n",
        "import unicodedata\n",
        "\n",
        "# --- Config ---\n",
        "NOTION_TOKEN = userdata.get(\"NOTION_API\")\n",
        "ROOT_PAGE_ID = \"2ee0a735274f80b6a961ee81eed44b06\"\n",
        "NOTION_VERSION = \"2025-09-03\"\n",
        "\n",
        "if not NOTION_TOKEN:\n",
        "    raise RuntimeError(\"NOTION_API not found in userdata secrets\")\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {NOTION_TOKEN}\",\n",
        "    \"Notion-Version\": NOTION_VERSION,\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "# --- HTTP helper ---\n",
        "def notion_get(url: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "    r = requests.get(url, headers=HEADERS, params=params)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "# --- Notion API helper ---\n",
        "def list_block_children(block_id: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Fetch all child blocks of a block/page (paginated).\"\"\"\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    url = f\"https://api.notion.com/v1/blocks/{block_id}/children\"\n",
        "    cursor = None\n",
        "    while True:\n",
        "        params = {\"start_cursor\": cursor} if cursor else None\n",
        "        data = notion_get(url, params=params)\n",
        "        results.extend(data.get(\"results\", []))\n",
        "        if not data.get(\"has_more\"):\n",
        "            break\n",
        "        cursor = data.get(\"next_cursor\")\n",
        "    return results\n",
        "\n",
        "# --- Markdown-ish text extraction ---\n",
        "def rich_text_to_plain(rt: List[Dict[str, Any]]) -> str:\n",
        "    return \"\".join(x.get(\"plain_text\", \"\") for x in (rt or []))\n",
        "\n",
        "def normalize(text: str) -> str:\n",
        "    return unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "def block_to_markdown_line(block: Dict[str, Any], indent: int) -> str:\n",
        "    \"\"\"\n",
        "    Convert a Notion block to a single Markdown line (no trailing newline).\n",
        "    Uses markdown tokens (#, ##, -, 1., >, ```).\n",
        "    \"\"\"\n",
        "    t = block.get(\"type\")\n",
        "    prefix_indent = \"  \" * indent  # indentation for nested blocks\n",
        "\n",
        "    # Headings -> markdown headings (keeps raw # tokens in output)\n",
        "    if t == \"heading_1\":\n",
        "        txt = rich_text_to_plain(block[\"heading_1\"].get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}# {txt}\".rstrip()\n",
        "    if t == \"heading_2\":\n",
        "        txt = rich_text_to_plain(block[\"heading_2\"].get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}## {txt}\".rstrip()\n",
        "    if t == \"heading_3\":\n",
        "        txt = rich_text_to_plain(block[\"heading_3\"].get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}### {txt}\".rstrip()\n",
        "\n",
        "    # Paragraph-like\n",
        "    if t == \"paragraph\":\n",
        "        txt = rich_text_to_plain(block[\"paragraph\"].get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}{txt}\".rstrip()\n",
        "\n",
        "    # Lists\n",
        "    if t == \"bulleted_list_item\":\n",
        "        txt = rich_text_to_plain(block[\"bulleted_list_item\"].get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}- {txt}\".rstrip()\n",
        "\n",
        "    if t == \"numbered_list_item\":\n",
        "        txt = rich_text_to_plain(block[\"numbered_list_item\"].get(\"rich_text\", []))\n",
        "        # We don’t know the true numbering from the API alone; use \"1.\" consistently.\n",
        "        return f\"{prefix_indent}1. {txt}\".rstrip()\n",
        "\n",
        "    # To-do\n",
        "    if t == \"to_do\":\n",
        "        obj = block[\"to_do\"]\n",
        "        checked = obj.get(\"checked\", False)\n",
        "        txt = rich_text_to_plain(obj.get(\"rich_text\", []))\n",
        "        box = \"x\" if checked else \" \"\n",
        "        return f\"{prefix_indent}- [{box}] {txt}\".rstrip()\n",
        "\n",
        "    # Quote / Callout\n",
        "    if t == \"quote\":\n",
        "        txt = rich_text_to_plain(block[\"quote\"].get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}> {txt}\".rstrip()\n",
        "\n",
        "    if t == \"callout\":\n",
        "        obj = block[\"callout\"]\n",
        "        txt = rich_text_to_plain(obj.get(\"rich_text\", []))\n",
        "        icon = obj.get(\"icon\")\n",
        "        icon_txt = \"\"\n",
        "        if isinstance(icon, dict) and icon.get(\"type\") == \"emoji\":\n",
        "            icon_txt = icon.get(\"emoji\", \"\") + \" \"\n",
        "        # Render as blockquote style so it stays “documentation-like”\n",
        "        return f\"{prefix_indent}> {icon_txt}{txt}\".rstrip()\n",
        "\n",
        "    # Code\n",
        "    if t == \"code\":\n",
        "        obj = block[\"code\"]\n",
        "        lang = obj.get(\"language\", \"\")\n",
        "        code = rich_text_to_plain(obj.get(\"rich_text\", []))\n",
        "        return f\"{prefix_indent}```{lang}\\n{code}\\n{prefix_indent}```\".rstrip()\n",
        "\n",
        "    # Divider\n",
        "    if t == \"divider\":\n",
        "        return f\"{prefix_indent}---\"\n",
        "\n",
        "    # Images\n",
        "    if t == \"image\":\n",
        "        caption = rich_text_to_plain(block[\"image\"].get(\"caption\", []))\n",
        "        return f\"{prefix_indent}{caption}\".rstrip() if caption.strip() else f\"{prefix_indent}[image]\"\n",
        "\n",
        "    # Subpage marker (we will recurse into it as blocks)\n",
        "    if t == \"child_page\":\n",
        "        title = block.get(\"child_page\", {}).get(\"title\", \"Untitled page\")\n",
        "        return f\"{prefix_indent}# {title}\".rstrip()\n",
        "\n",
        "    # Fallback (keeps your pipeline robust)\n",
        "    return f\"{prefix_indent}[{t}]\"\n",
        "\n",
        "def walk_page_as_markdown(root_block_id: str, indent: int = 0, visited: Optional[Set[str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Recursively read an entire Notion page (and any child pages beneath it),\n",
        "    returning a Markdown-like document that preserves headings/lists/code blocks.\n",
        "    No database logic included.\n",
        "    \"\"\"\n",
        "    if visited is None:\n",
        "        visited = set()\n",
        "\n",
        "    if root_block_id in visited:\n",
        "        return \"\"\n",
        "    visited.add(root_block_id)\n",
        "\n",
        "    lines: List[str] = []\n",
        "    children = list_block_children(root_block_id)\n",
        "\n",
        "    for b in children:\n",
        "        line = block_to_markdown_line(b, indent).rstrip()\n",
        "        if line.strip():\n",
        "            lines.append(line)\n",
        "\n",
        "        if b.get(\"has_children\"):\n",
        "            # recurse into nested blocks / toggles / child pages\n",
        "            nested = walk_page_as_markdown(b[\"id\"], indent=indent + 1, visited=visited)\n",
        "            if nested.strip():\n",
        "                lines.append(nested)\n",
        "\n",
        "    return normalize(\"\\n\".join(lines)).strip()\n",
        "\n",
        "\n",
        "# ---- Run ----\n",
        "md_text = walk_page_as_markdown(ROOT_PAGE_ID)\n",
        "# print(md_text[:2000])  # preview\n",
        "# Full markdown doc is in `md_text`\n"
      ],
      "metadata": {
        "id": "-5RwTV2KQoef"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = sum(\n",
        "    1 for line in md_text.splitlines()\n",
        "    if line.lstrip().startswith(\"## \")\n",
        ")\n",
        "count\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd9GpUNgQuvQ",
        "outputId": "ffd9f33c-fcf3-4c0d-9632-6c190e347846"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "PMrhpywVikH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931bd1ac-93f8-49c3-f761-cd5e30b5d1d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25 chunks\n",
            "--- Chunk 1: Introduction ---\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "A company that gives oral exams based on material uploaded.\n",
            "\n",
            "--- Chunk 2: Description: ---\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## Description:\n",
            "A platform that automatically generates and administers oral examinations based on user-uploaded materials. Educators, institutions, or com\n",
            "\n",
            "--- Chunk 3: What It Is ---\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## What It Is\n",
            "  A platform for conducting structured oral evaluations that assess how clearly individuals articulate, reason through, and communicate their\n",
            "\n",
            "--- Chunk 4: The Problem ---\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## The Problem\n",
            "  Traditional evaluation methods often fail to measure how well someone truly understands and can explain an idea.\n",
            "  - Written exams priorit\n",
            "\n",
            "--- Chunk 5: The Solution ---\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## The Solution\n",
            "  This platform makes oral evaluation scalable, structured, and consistent.\n",
            "  Participants engage in guided oral sessions where they must:\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def chunk_document(content: str, filename: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Chunk a markdown document by H2 (##) headers, allowing indentation, and\n",
        "    ignoring headers inside fenced code blocks.\n",
        "\n",
        "    Each chunk includes:\n",
        "    - The document title (# header) for context\n",
        "    - The section content (starting at its ## header)\n",
        "    - Metadata about the source\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1) Extract document title (# ...) (allow indentation too) ---\n",
        "    title_match = re.search(r'^\\s*#\\s+(.+?)\\s*$', content, re.MULTILINE)\n",
        "    doc_title = title_match.group(1) if title_match else filename\n",
        "\n",
        "    # --- 2) Remove (or neutralize) fenced code blocks to avoid false headers inside them ---\n",
        "    # We'll replace code block bodies with whitespace of the same length so indices stay aligned.\n",
        "    fence_pattern = re.compile(r\"(^|\\n)(```.*?\\n.*?\\n```)\", re.DOTALL)\n",
        "    masked = content\n",
        "    for m in fence_pattern.finditer(content):\n",
        "        block = m.group(2)\n",
        "        masked = masked.replace(block, \"\\n\" + (\" \" * (len(block) - 1)), 1)\n",
        "\n",
        "    # --- 3) Find all H2 headers (##), allowing indentation ---\n",
        "    h2_pattern = re.compile(r'^\\s*##\\s+.+$', re.MULTILINE)\n",
        "    matches = list(h2_pattern.finditer(masked))\n",
        "\n",
        "    chunks: List[Dict[str, Any]] = []\n",
        "\n",
        "    # If there are no H2 headers, return whole doc as single chunk\n",
        "    if not matches:\n",
        "        return [{\"content\": content, \"metadata\": {\"source_file\": filename, \"section_title\": doc_title}}]\n",
        "\n",
        "    # Optional: include intro chunk for content before first ## (if meaningful)\n",
        "    first_start = matches[0].start()\n",
        "    intro = content[:first_start].strip()\n",
        "    if intro:\n",
        "        chunk_content = f\"[From: {filename}]\\n# {doc_title}\\n\\n{intro}\"\n",
        "        chunks.append({\n",
        "            \"content\": chunk_content,\n",
        "            \"metadata\": {\n",
        "                \"source_file\": filename,\n",
        "                \"section_title\": \"Introduction\",\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # --- 4) Slice sections by header positions ---\n",
        "    for i, m in enumerate(matches):\n",
        "        start = m.start()\n",
        "        end = matches[i + 1].start() if i + 1 < len(matches) else len(content)\n",
        "        section = content[start:end].strip()\n",
        "        if not section:\n",
        "            continue\n",
        "\n",
        "        # Extract the section title from the first H2 line in the section (allow indentation)\n",
        "        section_title_match = re.search(r'^\\s*##\\s+(.+?)\\s*$', section, re.MULTILINE)\n",
        "        section_title = section_title_match.group(1) if section_title_match else \"Untitled Section\"\n",
        "\n",
        "        chunk_content = f\"[From: {filename}]\\n# {doc_title}\\n\\n{section}\"\n",
        "\n",
        "        chunks.append({\n",
        "            \"content\": chunk_content,\n",
        "            \"metadata\": {\n",
        "                \"source_file\": filename,\n",
        "                \"section_title\": section_title,\n",
        "            }\n",
        "        })\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Usage\n",
        "chunks = chunk_document(md_text, \"articulation.md\")\n",
        "print(f\"Found {len(chunks)} chunks\")\n",
        "for i, chunk in enumerate(chunks[:5]):\n",
        "    print(f\"--- Chunk {i+1}: {chunk['metadata']['section_title']} ---\")\n",
        "    print(chunk[\"content\"][:200])\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6NugL6hikH9"
      },
      "source": [
        "---\n",
        "## Part 3: Local Embeddings with MiniLM-L6-v2\n",
        "\n",
        "We use `fastembed` to run the MiniLM-L6-v2 model locally via ONNX. This means:\n",
        "- **No API calls** - Everything runs on your machine\n",
        "- **Fast inference** - ONNX runtime optimizations\n",
        "- **384 dimensions** - Compact but effective embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2nW7cGioikH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07474c2c-2ce8-4bbf-8ec5-c31775872f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MiniLM-L6-v2 embedding model (ONNX)...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from fastembed import TextEmbedding\n",
        "\n",
        "# Suppress Hugging Face token warning\n",
        "os.environ[\"HF_HUB_DISABLE_IMPLICIT_TOKEN\"] = \"1\"\n",
        "\n",
        "# Initialize the embedding model (downloads on first use)\n",
        "print(\"Loading MiniLM-L6-v2 embedding model (ONNX)...\")\n",
        "embedding_model = TextEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Gnr9-oOWikH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5823d0-7f80-47f1-8cfa-b867ce462561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: 'Artificial intelligence is transforming how businesses operate.'\n",
            "Embedding dimensions: 384\n",
            "First 10 values: [0.035499076629084546, 0.00839253664254505, 0.05062492341224551, -0.007122231672038325, -0.01755316620916984, 0.006484544607462985, -0.001429692512319824, 0.0006524717970323388, 0.014390853328519674, -0.02782975465926638]\n"
          ]
        }
      ],
      "source": [
        "def generate_embedding(text: str) -> list[float]:\n",
        "    \"\"\"Generate a 384-dimensional embedding for the given text.\"\"\"\n",
        "    embeddings = list(embedding_model.embed([text]))\n",
        "    return embeddings[0].tolist()\n",
        "\n",
        "def generate_embeddings_batch(texts: list[str]) -> list[list[float]]:\n",
        "    \"\"\"Generate embeddings for multiple texts in a batch (more efficient).\"\"\"\n",
        "    if not texts:\n",
        "        return []\n",
        "    embeddings = list(embedding_model.embed(texts))\n",
        "    return [emb.tolist() for emb in embeddings]\n",
        "\n",
        "# Test it out\n",
        "test_text = \"Artificial intelligence is transforming how businesses operate.\"\n",
        "test_embedding = generate_embedding(test_text)\n",
        "\n",
        "print(f\"Input text: '{test_text}'\")\n",
        "print(f\"Embedding dimensions: {len(test_embedding)}\")\n",
        "print(f\"First 10 values: {test_embedding[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "WYIiMQ7CikH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b3b3c9-fc1c-423b-c7d5-a35c5fe59338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 25 embeddings to database (using sqlite-vec)\n"
          ]
        }
      ],
      "source": [
        "import struct\n",
        "\n",
        "def serialize_embedding(embedding: list[float]) -> bytes:\n",
        "    \"\"\"Serialize embedding to binary format for sqlite-vec.\"\"\"\n",
        "    return struct.pack(f'{len(embedding)}f', *embedding)\n",
        "\n",
        "def save_embedding(conn, source_type: str, content: str, embedding: list[float],\n",
        "                   source_id: str = None, metadata: dict = None) -> int:\n",
        "    \"\"\"\n",
        "    Save an embedding to the database.\n",
        "\n",
        "    Inserts into:\n",
        "    1. embeddings_meta - content and metadata (FTS5 updated via trigger)\n",
        "    2. vec_embeddings - vector for similarity search (matched by rowid)\n",
        "    \"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Insert metadata (FTS5 index updated automatically via trigger)\n",
        "    cursor.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO embeddings_meta (source_type, source_id, content, metadata, created_at)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (\n",
        "            source_type,\n",
        "            source_id,\n",
        "            content,\n",
        "            json.dumps(metadata) if metadata else None,\n",
        "            datetime.now().isoformat(),\n",
        "        ),\n",
        "    )\n",
        "    rowid = cursor.lastrowid\n",
        "\n",
        "    # Insert vector with matching rowid\n",
        "    cursor.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO vec_embeddings (rowid, embedding)\n",
        "        VALUES (?, ?)\n",
        "        \"\"\",\n",
        "        (rowid, serialize_embedding(embedding)),\n",
        "    )\n",
        "\n",
        "    conn.commit()\n",
        "    return rowid\n",
        "\n",
        "# Embed and save the sample chunks\n",
        "for chunk in chunks:\n",
        "    embedding = generate_embedding(chunk[\"content\"])\n",
        "    save_embedding(\n",
        "        db,\n",
        "        source_type=\"business_doc\",\n",
        "        content=chunk[\"content\"],\n",
        "        embedding=embedding,\n",
        "        source_id=\"company.md\",\n",
        "        metadata=chunk[\"metadata\"],\n",
        "    )\n",
        "\n",
        "print(f\"Saved {len(chunks)} embeddings to database (using sqlite-vec)\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5624632e"
      },
      "source": [
        "# (Optional) Environment inspection - no longer needed as we use manual input\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcCiv1QNikH9"
      },
      "source": [
        "### Embed Business Documents\n",
        "\n",
        "Let's embed the actual business documents from the project. Add your files to the business-docs folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nT3l8XbPikH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff6c04d-2e23-440f-f425-90335501ec05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 document(s) to embed\n",
            "\n",
            "Processing: Articulate 2ee0a735274f80b6a961ee81eed44b06.md\n",
            "  Saved 2 chunk(s)\n",
            "\n",
            "Total embeddings created: 2\n"
          ]
        }
      ],
      "source": [
        "# BUSINESS_DOCS_DIR = Path(\"business-docs\")\n",
        "\n",
        "# # Create the directory so it's visible in the file browser\n",
        "# BUSINESS_DOCS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# def embed_business_docs(conn, docs_dir: Path):\n",
        "#     \"\"\"Embed all markdown files in the business docs directory.\"\"\"\n",
        "#     doc_files = list(docs_dir.glob(\"*.md\"))\n",
        "#     print(f\"Found {len(doc_files)} document(s) to embed\")\n",
        "\n",
        "#     total_chunks = 0\n",
        "#     for doc_path in doc_files:\n",
        "#         print(f\"\\nProcessing: {doc_path.name}\")\n",
        "#         content = doc_path.read_text()\n",
        "#         chunks = chunk_document(content, doc_path.name)\n",
        "\n",
        "#         # Batch generate embeddings\n",
        "#         texts = [c[\"content\"] for c in chunks]\n",
        "#         embeddings = generate_embeddings_batch(texts)\n",
        "\n",
        "#         # Save each chunk (to both embeddings_meta and vec_embeddings)\n",
        "#         for chunk, embedding in zip(chunks, embeddings):\n",
        "#             save_embedding(\n",
        "#                 conn,\n",
        "#                 source_type=\"business_doc\",\n",
        "#                 content=chunk[\"content\"],\n",
        "#                 embedding=embedding,\n",
        "#                 source_id=doc_path.name,\n",
        "#                 metadata=chunk[\"metadata\"],\n",
        "#             )\n",
        "\n",
        "#         print(f\"  Saved {len(chunks)} chunk(s)\")\n",
        "#         total_chunks += len(chunks)\n",
        "\n",
        "#     return total_chunks\n",
        "\n",
        "# if list(BUSINESS_DOCS_DIR.glob(\"*.md\")):\n",
        "#     total = embed_business_docs(db, BUSINESS_DOCS_DIR)\n",
        "#     print(f\"\\nTotal embeddings created: {total}\")\n",
        "# else:\n",
        "#     print(f\"No markdown files found in {BUSINESS_DOCS_DIR.absolute()}\")\n",
        "#     print(\"Please upload some .md files to the 'business-docs' folder!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dRl4tlGikH9"
      },
      "source": [
        "## Part 4: Hybrid Search (BM25 + Semantic)\n",
        "\n",
        "Hybrid search combines:\n",
        "1. **BM25 keyword search** via SQLite FTS5\n",
        "2. **Semantic search** via sqlite-vec native cosine distance\n",
        "\n",
        "### Why Hybrid?\n",
        "\n",
        "| Query Type | BM25 | Semantic | Best Choice |\n",
        "|------------|------|----------|-------------|\n",
        "| \"Emanon AI\" | ✅ Exact match | ❌ May miss | BM25 |\n",
        "| \"help with machine learning\" | ❌ No exact terms | ✅ Semantic match | Semantic |\n",
        "| \"Emanon consulting services\" | ✅ \"Emanon\" match | ✅ \"consulting\" related | **Hybrid!** |\n",
        "\n",
        "### sqlite-vec Benefits\n",
        "\n",
        "| Aspect | JSON Blobs (old) | sqlite-vec (new) |\n",
        "|--------|------------------|------------------|\n",
        "| Search | Load all → NumPy | Native SQL MATCH |\n",
        "| Speed | O(n) full scan | Optimized ANN |\n",
        "| Storage | ~4x larger (JSON) | Compact binary |\n",
        "| Scalability | <10k vectors | Millions |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Gva0eS5QikH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b0ce87-8d9e-4580-81b3-bcc2a2bd336d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ID 4: score = -3.4766\n",
            "  ID 5: score = -1.9010\n",
            "  ID 8: score = -2.1337\n"
          ]
        }
      ],
      "source": [
        "def bm25_search(conn, query: str, limit: int = 100) -> dict[int, float]:\n",
        "    \"\"\"\n",
        "    Search using BM25 ranking via FTS5.\n",
        "\n",
        "    Returns dict mapping embedding_id to raw BM25 score.\n",
        "    Note: FTS5 BM25 scores are NEGATIVE (more negative = better match).\n",
        "    \"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Escape special FTS5 characters\n",
        "    safe_query = query.replace('\"', '\"\"')\n",
        "\n",
        "    try:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT rowid, bm25(embeddings_fts) as score\n",
        "            FROM embeddings_fts\n",
        "            WHERE embeddings_fts MATCH ?\n",
        "            LIMIT ?\n",
        "        \"\"\", (safe_query, limit))\n",
        "\n",
        "        return {row[0]: row[1] for row in cursor.fetchall()}\n",
        "    except sqlite3.OperationalError:\n",
        "        # No matches or invalid query\n",
        "        return {}\n",
        "\n",
        "# Test BM25 search\n",
        "test_query = \"articulate\"\n",
        "bm25_results = bm25_search(db, test_query)\n",
        "for emb_id, score in list(bm25_results.items())[:3]:\n",
        "    print(f\"  ID {emb_id}: score = {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amJ4svDpBJcy",
        "outputId": "4b0ff554-1d28-4dbe-f18f-10cfa15863e3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: -3.4766046747912225,\n",
              " 5: -1.9010206491387,\n",
              " 8: -2.133674850241169,\n",
              " 16: -1.6006770781871287}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "pmerQAwkikH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4f74d0-def1-495a-e20d-a6a30f28cd69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic search for 'How can this produce help me?' found 5 results:\n",
            "  ID 22: distance = 0.7262 (similarity = 0.6369)\n",
            "  ID 19: distance = 0.7315 (similarity = 0.6342)\n",
            "  ID 16: distance = 0.7346 (similarity = 0.6327)\n",
            "  ID 25: distance = 0.7579 (similarity = 0.6210)\n",
            "  ID 20: distance = 0.7583 (similarity = 0.6208)\n"
          ]
        }
      ],
      "source": [
        "def semantic_search(conn, query_embedding: list[float], limit: int = 100) -> dict[int, float]:\n",
        "    \"\"\"\n",
        "    Search using sqlite-vec's native cosine distance.\n",
        "\n",
        "    Returns dict mapping rowid to cosine distance.\n",
        "    Note: cosine distance is in [0, 2] where 0 = identical, 2 = opposite.\n",
        "    \"\"\"\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # sqlite-vec requires 'k = ?' in the WHERE clause when using a parameterized limit\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT rowid, distance\n",
        "        FROM vec_embeddings\n",
        "        WHERE embedding MATCH ?\n",
        "          AND k = ?\n",
        "        ORDER BY distance\n",
        "    \"\"\", (serialize_embedding(query_embedding), limit))\n",
        "\n",
        "    return {row[0]: row[1] for row in cursor.fetchall()}\n",
        "\n",
        "# Test semantic search\n",
        "test_query = \"How can this produce help me?\"\n",
        "\n",
        "test_emb = generate_embedding(test_query)\n",
        "semantic_results = semantic_search(db, test_emb, limit=5)\n",
        "\n",
        "print(f\"Semantic search for '{test_query}' found {len(semantic_results)} results:\")\n",
        "for rowid, distance in list(semantic_results.items()):\n",
        "    print(f\"  ID {rowid}: distance = {distance:.4f} (similarity = {1 - distance/2:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PLivN0WxikH-"
      },
      "outputs": [],
      "source": [
        "def normalize_bm25_scores(bm25_scores: dict[int, float]) -> dict[int, float]:\n",
        "    \"\"\"\n",
        "    Normalize BM25 scores to [0, 1] range.\n",
        "\n",
        "    FTS5 BM25 scores are negative (more negative = better).\n",
        "    We invert so that best match gets 1.0, worst gets 0.0.\n",
        "    \"\"\"\n",
        "    if not bm25_scores:\n",
        "        return {}\n",
        "\n",
        "    scores = list(bm25_scores.values())\n",
        "    min_score = min(scores)  # Most negative = best\n",
        "    max_score = max(scores)  # Least negative = worst\n",
        "\n",
        "    if min_score == max_score:\n",
        "        return {id: 1.0 for id in bm25_scores}\n",
        "\n",
        "    score_range = max_score - min_score\n",
        "    return {\n",
        "        id: (max_score - score) / score_range\n",
        "        for id, score in bm25_scores.items()\n",
        "    }\n",
        "\n",
        "def normalize_distances(distances: dict[int, float]) -> dict[int, float]:\n",
        "    \"\"\"\n",
        "    Normalize cosine distances to similarity scores in [0, 1].\n",
        "\n",
        "    Cosine distance is in [0, 2] where 0 = identical.\n",
        "    We convert to similarity: 1 - (distance / 2)\n",
        "    Then normalize so best match gets 1.0.\n",
        "    \"\"\"\n",
        "    if not distances:\n",
        "        return {}\n",
        "\n",
        "    # Convert distances to similarities\n",
        "    similarities = {id: 1 - (dist / 2) for id, dist in distances.items()}\n",
        "\n",
        "    # Normalize to [0, 1] range\n",
        "    min_sim = min(similarities.values())\n",
        "    max_sim = max(similarities.values())\n",
        "\n",
        "    if min_sim == max_sim:\n",
        "        return {id: 1.0 for id in similarities}\n",
        "\n",
        "    sim_range = max_sim - min_sim\n",
        "    return {\n",
        "        id: (sim - min_sim) / sim_range\n",
        "        for id, sim in similarities.items()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Fe-veiQOikH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1fc98a-10f5-460e-fe74-5839c2481d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid search for 'How can this produce help me?':\n",
            "\n",
            "1. Score: 0.500 (BM25: 0.000, Semantic: 1.000)\n",
            "   Source: company.md\n",
            "   Preview: [From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## General Users\n",
            "  “It made me a clearer thinker.”\n",
            "  Ex...\n",
            "\n",
            "2. Score: 0.490 (BM25: 0.000, Semantic: 0.980)\n",
            "   Source: company.md\n",
            "   Preview: [From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## Doctors and Medical Professionals\n",
            "  “It helped me pr...\n",
            "\n",
            "3. Score: 0.485 (BM25: 0.000, Semantic: 0.969)\n",
            "   Source: company.md\n",
            "   Preview: [From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## Students\n",
            "  “I finally feel evaluated on what I actua...\n",
            "\n",
            "4. Score: 0.441 (BM25: 0.000, Semantic: 0.883)\n",
            "   Source: company.md\n",
            "   Preview: [From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## Post-Exam Feedback (Generated by the Platform)\n",
            "  ###...\n",
            "\n",
            "5. Score: 0.441 (BM25: 0.000, Semantic: 0.881)\n",
            "   Source: company.md\n",
            "   Preview: [From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## Professionals and Interview Candidates\n",
            "  “It feels l...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_metadata_by_ids(conn, ids: list[int]) -> dict[int, dict]:\n",
        "    \"\"\"Retrieve metadata for given IDs from embeddings_meta table.\"\"\"\n",
        "    if not ids:\n",
        "        return {}\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    placeholders = \",\".join(\"?\" * len(ids))\n",
        "    cursor.execute(f\"\"\"\n",
        "        SELECT id, source_type, source_id, content, metadata\n",
        "        FROM embeddings_meta\n",
        "        WHERE id IN ({placeholders})\n",
        "    \"\"\", ids)\n",
        "\n",
        "    results = {}\n",
        "    for row in cursor.fetchall():\n",
        "        results[row[0]] = {\n",
        "            \"source_type\": row[1],\n",
        "            \"source_id\": row[2],\n",
        "            \"content\": row[3],\n",
        "            \"metadata\": json.loads(row[4]) if row[4] else {},\n",
        "        }\n",
        "    return results\n",
        "\n",
        "def hybrid_search(\n",
        "    conn,\n",
        "    query: str,\n",
        "    query_embedding: list[float],\n",
        "    keyword_weight: float = 0.5,\n",
        "    semantic_weight: float = 0.5,\n",
        "    top_k: int = 10,\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Perform hybrid search combining BM25 and sqlite-vec cosine similarity.\n",
        "\n",
        "    Formula: final_score = keyword_weight * bm25 + semantic_weight * cosine_sim\n",
        "\n",
        "    Args:\n",
        "        conn: Database connection\n",
        "        query: Search query text\n",
        "        query_embedding: Pre-computed embedding of the query\n",
        "        keyword_weight: Weight for BM25 (0-1)\n",
        "        semantic_weight: Weight for cosine similarity (0-1)\n",
        "        top_k: Number of results to return\n",
        "\n",
        "    Returns:\n",
        "        List of results sorted by combined score (highest first)\n",
        "    \"\"\"\n",
        "    # Step 1: Get BM25 scores from FTS5\n",
        "    bm25_raw = bm25_search(conn, query)\n",
        "    bm25_normalized = normalize_bm25_scores(bm25_raw)\n",
        "\n",
        "    # Step 2: Get semantic distances from sqlite-vec\n",
        "    semantic_raw = semantic_search(conn, query_embedding, limit=100)\n",
        "    semantic_normalized = normalize_distances(semantic_raw)\n",
        "\n",
        "    # Step 3: Get all unique IDs from both searches\n",
        "    all_ids = set(bm25_normalized.keys()) | set(semantic_normalized.keys())\n",
        "\n",
        "    if not all_ids:\n",
        "        return []\n",
        "\n",
        "    # Step 4: Get metadata for all candidates\n",
        "    metadata = get_metadata_by_ids(conn, list(all_ids))\n",
        "\n",
        "    # Step 5: Compute combined scores\n",
        "    scored_results = []\n",
        "\n",
        "    for id in all_ids:\n",
        "        # BM25 score (0 if no keyword match)\n",
        "        bm25_score = bm25_normalized.get(id, 0.0)\n",
        "\n",
        "        # Semantic score (0 if not in top semantic results)\n",
        "        semantic_score = semantic_normalized.get(id, 0.0)\n",
        "\n",
        "        # Combined score\n",
        "        final_score = (keyword_weight * bm25_score) + (semantic_weight * semantic_score)\n",
        "\n",
        "        meta = metadata.get(id, {})\n",
        "        scored_results.append({\n",
        "            \"id\": id,\n",
        "            \"content\": meta.get(\"content\", \"\"),\n",
        "            \"source_type\": meta.get(\"source_type\", \"\"),\n",
        "            \"source_id\": meta.get(\"source_id\", \"\"),\n",
        "            \"metadata\": meta.get(\"metadata\", {}),\n",
        "            \"bm25_score\": bm25_score,\n",
        "            \"semantic_score\": semantic_score,\n",
        "            \"final_score\": final_score,\n",
        "        })\n",
        "\n",
        "    # Sort by final score (descending)\n",
        "    scored_results.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
        "\n",
        "    return scored_results[:top_k]\n",
        "\n",
        "# Test hybrid search\n",
        "query_emb = generate_embedding(test_query)\n",
        "\n",
        "results = hybrid_search(db, test_query, query_emb, top_k=5)\n",
        "\n",
        "print(f\"Hybrid search for '{test_query}':\\n\")\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"{i}. Score: {r['final_score']:.3f} (BM25: {r['bm25_score']:.3f}, Semantic: {r['semantic_score']:.3f})\")\n",
        "    print(f\"   Source: {r['source_id']}\")\n",
        "    print(f\"   Preview: {r['content'][:100]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz1HDdkFikH-"
      },
      "source": [
        "---\n",
        "## Part 5: Post Generation with RAG Context\n",
        "\n",
        "Now we combine everything: retrieve relevant context and generate a post."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "NMeb_Fu3ikH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb2fa72-dcb3-4574-f197-2f93d7141087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved context:\n",
            "\n",
            "[1. business_doc] (score: 0.81)\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## The Solution\n",
            "  This platform makes oral evaluation scalable, structured, and consistent.\n",
            "  Participants engage in guided oral sessions where they must:\n",
            "  - Explain concepts in their own words\n",
            "  - Respond to follow-up questions\n",
            "  - Clarify ambiguous answers\n",
            "  - Defend or refine their reasoning\n",
            "  The system adapts in real time and evaluates responses using predefined criteria and rubrics.\n",
            "  ---\n",
            "\n",
            "[2. business_doc] (score: 0.78)\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## The Problem\n",
            "  Traditional evaluation methods often fail to measure how well someone truly understands and can explain an idea.\n",
            "  - Written exams prioritize memorization and speed over reasoning\n",
            "  - Plagiarism and AI-generated text undermine assessment integrity\n",
            "  - Oral evaluations are high-signal but difficult to scale\n",
            "  - Communication skills—critical in academic and professional settings—are underassessed\n",
            "  ---\n",
            "\n",
            "[3. business_doc] (score: 0.77)\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## Why Now\n",
            "  As written assessments become easier to automate and manipulate, how someone explains an idea is becoming the most reliable signal of understanding.\n",
            "  This platform meets that moment—bringing rigor, structure, and scale to oral evaluation.\n",
            "  ---\n",
            "\n",
            "[4. business_doc] (score: 0.74)\n",
            "[From: articulation.md]\n",
            "# Platform Overview\n",
            "\n",
            "## What Makes It Different\n",
            "  - Dialogue-based: Evaluates thinking through conversation, not forms\n",
            "  - Adaptive...\n"
          ]
        }
      ],
      "source": [
        "def format_context_for_prompt(results: list[dict], max_chars: int = 4000) -> str:\n",
        "    \"\"\"Format search results into context for the LLM prompt.\"\"\"\n",
        "    if not results:\n",
        "        return \"No relevant context found.\"\n",
        "\n",
        "    context_parts = []\n",
        "    chars_used = 0\n",
        "\n",
        "    for i, result in enumerate(results, 1):\n",
        "        header = f\"[{i}. {result['source_type']}] (score: {result['final_score']:.2f})\"\n",
        "        content = result[\"content\"]\n",
        "\n",
        "        available = max_chars - chars_used - len(header) - 10\n",
        "        if available <= 100:\n",
        "            break\n",
        "\n",
        "        if len(content) > available:\n",
        "            content = content[:available - 3] + \"...\"\n",
        "\n",
        "        entry = f\"{header}\\n{content}\\n\"\n",
        "        context_parts.append(entry)\n",
        "        chars_used += len(entry)\n",
        "\n",
        "    return \"\\n\".join(context_parts)\n",
        "\n",
        "def retrieve_context(conn, query: str, top_k: int = 10) -> tuple[str, list[dict]]:\n",
        "    \"\"\"High-level function to retrieve and format context for RAG.\"\"\"\n",
        "    query_embedding = generate_embedding(query)\n",
        "    results = hybrid_search(conn, query, query_embedding, top_k=top_k)\n",
        "    formatted = format_context_for_prompt(results)\n",
        "    return formatted, results\n",
        "\n",
        "# Test context retrieval\n",
        "context, results = retrieve_context(db, \"Oral Evaluation\")\n",
        "print(\"Retrieved context:\\n\")\n",
        "print(context[:1500] + \"...\" if len(context) > 1500 else context)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"]  = userdata.get(\"OPENROUTER_API_KEY\") or \"YOUR_API_KEY_HERE\""
      ],
      "metadata": {
        "id": "gapu7ajr6hGM"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import date, timedelta\n",
        "from typing import List\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Structured output schemas\n",
        "# -----------------------------\n",
        "class Status(BaseModel):\n",
        "    status: str = Field(\n",
        "        min_length=3,\n",
        "        description=\"The post text to publish on Mastodon (<= 100 words).\"\n",
        "    )\n",
        "    date_posted: date = Field(\n",
        "        description=\"Target date for posting (YYYY-MM-DD).\"\n",
        "    )\n",
        "    content: str = Field(\n",
        "        description=\"Short internal rationale or angle for the post (not posted).\"\n",
        "    )\n",
        "\n",
        "class StatusList(BaseModel):\n",
        "    posts: List[Status] = Field(\n",
        "        min_length=1,\n",
        "        description=\"List of generated posts.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# OpenRouter via OpenAI SDK\n",
        "# -----------------------------\n",
        "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")\n",
        "if not OPENROUTER_API_KEY:\n",
        "    raise RuntimeError(\"Missing OPENROUTER_API_KEY\")\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        ")\n",
        "\n",
        "\n",
        "def generate_posts_with_rag(context: str, topic: str) -> StatusList:\n",
        "    \"\"\"\n",
        "    Generate exactly 10 Mastodon posts using ONLY the provided RAG context.\n",
        "    Uses `text_format` to enforce structured JSON output.\n",
        "    \"\"\"\n",
        "    today = date.today()\n",
        "    target_dates = [(today + timedelta(days=i)).isoformat() for i in range(10)]\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a social media manager for a platform that evaluates how clearly people \"\n",
        "        \"articulate and communicate their ideas through oral evaluation and practice.\\n\\n\"\n",
        "        \"Rules:\\n\"\n",
        "        \"- Use ONLY the provided context\\n\"\n",
        "        \"- Each post must be <= 100 words\\n\"\n",
        "        \"- Include 1–2 relevant hashtags\\n\"\n",
        "        \"- Avoid hype or guarantees\\n\"\n",
        "        \"- Generate exactly 10 distinct posts\\n\"\n",
        "        \"- Output MUST conform to the provided schema\\n\"\n",
        "    )\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"Context (use only this):\\n{context}\\n\\n\"\n",
        "        f\"Topic to emphasize: {topic}\\n\\n\"\n",
        "        f\"Use these posting dates IN ORDER:\\n{target_dates}\\n\\n\"\n",
        "        \"Return 10 posts mentioning the company's name (Articulate). For each post:\\n\"\n",
        "        \"- status: Mastodon post text\\n\"\n",
        "        \"- date_posted: one of the provided dates\\n\"\n",
        "        \"- content: internal rationale or angle (not posted)\\n\"\n",
        "\n",
        "    )\n",
        "\n",
        "    posts = client.responses.parse(\n",
        "        model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
        "        input=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ],\n",
        "        text_format=StatusList,\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    posts = client.responses.parse(\n",
        "      model=\"nvidia/nemotron-3-nano-30b-a3b:free\",\n",
        "      input= instructions,\n",
        "      text_format=StatusList,\n",
        "  )\n",
        "    \"\"\"\n",
        "\n",
        "    # Parsed + validated against StatusList\n",
        "    return posts"
      ],
      "metadata": {
        "id": "TPg6ulWN8a-V"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Example usage\n",
        "# -----------------------------\n",
        "topic = \"Good scalable oral exams and articulation-focused assessment\"\n",
        "context, _ = retrieve_context(db, topic)  # your existing RAG function\n",
        "statuses = generate_posts_with_rag(context, topic)\n",
        "# posts = statuses.posts  # <-- variable holding the 10 posts\n",
        "# print(posts[0])"
      ],
      "metadata": {
        "id": "I2vh_87SiLex"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type(statuses)\n",
        "posts = (\n",
        "    getattr(statuses, \"output_parsed\", None)\n",
        "    or getattr(statuses, \"parsed\", None)\n",
        "    or statuses\n",
        ")\n"
      ],
      "metadata": {
        "id": "Aa_fD_7KiQDO"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for post in posts.posts:\n",
        "    print('-------------post---------------')\n",
        "    print(post.status[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EchbKF1SioXj",
        "outputId": "5960120a-0b39-4a8c-a525-62c083f3d8da"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------post---------------\n",
            "Articulate lets educators run structured oral exams at scale, revealing true understanding beyond memorization.\n",
            "-------------post---------------\n",
            "With Articulate, teachers gain clearer insight into student comprehension through live oral questioning and adaptive follow‑ups.\n",
            "-------------post---------------\n",
            "Students using Articulate report confidence gains, practicing articulation in low‑stakes, structured oral assessments.\n",
            "-------------post---------------\n",
            "Articulate adapts to each answer, probing depth and clarifying reasoning, ensuring consistent evaluation across classes.\n",
            "-------------post---------------\n",
            "By uploading any material, Articulate automatically designs oral exams that test reasoning, not just rote recall.\n",
            "-------------post---------------\n",
            "The platform’s rubric‑driven evaluation gives reliable feedback, helping learners pinpoint where their understanding breaks down.\n",
            "-------------post---------------\n",
            "Articulate’s oral exams simulate real‑world communication contexts, preparing users for interviews and presentations.\n",
            "-------------post---------------\n",
            "Educators appreciate that Articulate scales oral evaluation without adding workload, preserving consistent rubrics.\n",
            "-------------post---------------\n",
            "The system’s adaptive questioning uncovers hidden misconceptions, turning oral exams into powerful diagnostic tools.\n",
            "-------------post---------------\n",
            "Through guided spoken explanations, Articulate helps users develop clearer articulation and stronger reasoning skills.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKEbeDHkikH-"
      },
      "source": [
        "---\n",
        "## Part 6: Full Workflow Demo\n",
        "\n",
        "Putting it all together: detect changes → retrieve context → generate post"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qsOg7ITyBRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import hashlib\n",
        "\n",
        "# POLL_INTERVAL_SECONDS = 120  # every 2 minutes\n",
        "# STATE_FILE = \"notion_watch_state.json\"\n",
        "# OUTPUT_FILE = \"generated_posts.json\"\n",
        "# MASTODON_TOKEN = userdata.get(\"MASTODON_TOKEN\") or \"YOUR_MASTODON_TOKEN_HERE\"\n",
        "# MASTION_INSTANCE = \"https://mastodon.social\"\n",
        "\n",
        "# def notion_get(url: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
        "#     r = requests.get(url, headers=NOTION_HEADERS, params=params, timeout=30)\n",
        "#     r.raise_for_status()\n",
        "#     return r.json()\n",
        "\n",
        "# def get_page_meta(page_id: str) -> Dict[str, Any]:\n",
        "#     return notion_get(f\"https://api.notion.com/v1/pages/{page_id}\")\n",
        "\n",
        "# def list_block_children(block_id: str) -> List[Dict[str, Any]]:\n",
        "#     results: List[Dict[str, Any]] = []\n",
        "#     url = f\"https://api.notion.com/v1/blocks/{block_id}/children\"\n",
        "#     cursor = None\n",
        "#     while True:\n",
        "#         params = {\"start_cursor\": cursor} if cursor else None\n",
        "#         data = notion_get(url, params=params)\n",
        "#         results.extend(data.get(\"results\", []))\n",
        "#         if not data.get(\"has_more\"):\n",
        "#             break\n",
        "#         cursor = data.get(\"next_cursor\")\n",
        "#     return results\n",
        "\n",
        "# # =========================\n",
        "# # STATE + OUTPUT\n",
        "# # =========================\n",
        "# # def load_state() -> Dict[str, Any]:\n",
        "# #     try:\n",
        "# #         with open(STATE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "# #             return json.load(f)\n",
        "# #     except FileNotFoundError:\n",
        "# #         return {\"pages\": {}}\n",
        "\n",
        "# # def save_state(state: Dict[str, Any]) -> None:\n",
        "# #     with open(STATE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "# #         json.dump(state, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# # def append_output(page_id: str, title: str, posts: StatusList) -> None:\n",
        "# #     record = {\n",
        "# #         \"page_id\": page_id,\n",
        "# #         \"title\": title,\n",
        "# #         \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "# #         \"posts\": [\n",
        "# #             {\n",
        "# #                 \"status\": p.status,\n",
        "# #                 \"date_posted\": p.date_posted.isoformat(),\n",
        "# #                 \"content\": p.content,\n",
        "# #             }\n",
        "# #             for p in posts.posts\n",
        "# #         ],\n",
        "# #     }\n",
        "# #     try:\n",
        "# #         existing = []\n",
        "# #         if os.path.exists(OUTPUT_FILE):\n",
        "# #             with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "# #                 existing = json.load(f)\n",
        "# #         existing.append(record)\n",
        "# #         with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "# #             json.dump(existing, f, ensure_ascii=False, indent=2)\n",
        "# #     except Exception as e:\n",
        "# #         print(f\"[Output] Failed writing output: {e}\")\n",
        "\n",
        "# # def discover_child_pages(root_page_id: str) -> Set[str]:\n",
        "# #     \"\"\"\n",
        "# #     Traverse the root page's block tree and collect IDs of all child pages.\n",
        "# #     Includes nested child pages.\n",
        "# #     \"\"\"\n",
        "# #     found: Set[str] = set()\n",
        "# #     stack = [root_page_id]\n",
        "# #     visited: Set[str] = set()\n",
        "\n",
        "# #     while stack:\n",
        "# #         block_id = stack.pop()\n",
        "# #         if block_id in visited:\n",
        "# #             continue\n",
        "# #         visited.add(block_id)\n",
        "\n",
        "# #         for b in list_block_children(block_id):\n",
        "# #             t = b.get(\"type\")\n",
        "\n",
        "# #             # If this block is a child page, record it and also traverse into it\n",
        "# #             if t == \"child_page\":\n",
        "# #                 child_id = b[\"id\"]\n",
        "# #                 found.add(child_id)\n",
        "# #                 stack.append(child_id)\n",
        "\n",
        "# #             # Traverse any other block that has children (toggles, callouts, etc.)\n",
        "# #             if b.get(\"has_children\"):\n",
        "# #                 stack.append(b[\"id\"])\n",
        "\n",
        "# #     return found\n",
        "\n",
        "# # def run_notion_poll_once_watch_root_tree(root_id: str):\n",
        "# #     \"\"\"\n",
        "# #     Poll changes for:\n",
        "# #       - the root page\n",
        "# #       - every child page discovered under the root (recursively)\n",
        "# #     \"\"\"\n",
        "# #     state = load_state()\n",
        "# #     pages_state = state[\"pages\"]\n",
        "\n",
        "# #     # 1) discover all pages under root\n",
        "# #     page_ids = {root_id} | discover_child_pages(root_id)\n",
        "\n",
        "# #     for page_id in sorted(page_ids):\n",
        "# #         meta = get_page_meta(page_id)\n",
        "# #         last_edited = meta.get(\"last_edited_time\")\n",
        "# #         title = page_title_from_meta(meta)\n",
        "\n",
        "# #         prev_last_edited = pages_state.get(page_id, {}).get(\"last_edited_time\")\n",
        "# #         if prev_last_edited == last_edited:\n",
        "# #             continue\n",
        "\n",
        "# #         print(f\"[Notion] Change detected on '{title}' ({page_id}). Generating posts...\")\n",
        "\n",
        "# #         md_text = walk_page_as_markdown(page_id)\n",
        "# #         posts = generate_posts_with_rag(md_text, title)\n",
        "# #         append_output(page_id, title, posts)\n",
        "\n",
        "# #         pages_state[page_id] = {\"last_edited_time\": last_edited}\n",
        "\n",
        "# #     save_state(state)\n",
        "\n",
        "\n",
        "# # -----------------------\n",
        "# # NOTION HELPERS\n",
        "# # -----------------------\n",
        "\n",
        "# def retrieve_page(page_id: str) -> Dict[str, Any]:\n",
        "#     return notion_get(f\"https://api.notion.com/v1/pages/{page_id}\")\n",
        "\n",
        "# def list_block_children(block_id: str) -> List[Dict[str, Any]]:\n",
        "#     results: List[Dict[str, Any]] = []\n",
        "#     url = f\"https://api.notion.com/v1/blocks/{block_id}/children\"\n",
        "#     cursor = None\n",
        "#     while True:\n",
        "#         params = {\"start_cursor\": cursor} if cursor else None\n",
        "#         data = notion_get(url, params=params)\n",
        "#         results.extend(data.get(\"results\", []))\n",
        "#         if not data.get(\"has_more\"):\n",
        "#             break\n",
        "#         cursor = data.get(\"next_cursor\")\n",
        "#     return results\n",
        "\n",
        "# def rich_text_to_plain(rt: List[Dict[str, Any]]) -> str:\n",
        "#     return \"\".join(x.get(\"plain_text\", \"\") for x in (rt or []))\n",
        "\n",
        "# def normalize(text: str) -> str:\n",
        "#     return unicodedata.normalize(\"NFKD\", text)\n",
        "\n",
        "# def page_title(page: Dict[str, Any]) -> str:\n",
        "#     props = page.get(\"properties\", {})\n",
        "#     for prop in props.values():\n",
        "#         if prop.get(\"type\") == \"title\":\n",
        "#             return rich_text_to_plain(prop.get(\"title\", [])) or \"Untitled\"\n",
        "#     return \"Untitled\"\n",
        "\n",
        "# def is_descendant_of_root(page_id: str, root_id: str, max_hops: int = 50) -> bool:\n",
        "#     \"\"\"\n",
        "#     Walk the parent chain: page -> parent.page_id -> ... until root or workspace.\n",
        "#     This lets you enforce \"only pages under root trigger generation\".\n",
        "#     \"\"\"\n",
        "#     current = page_id\n",
        "#     for _ in range(max_hops):\n",
        "#         if current == root_id:\n",
        "#             return True\n",
        "#         page = retrieve_page(current)\n",
        "#         parent = page.get(\"parent\", {})\n",
        "#         ptype = parent.get(\"type\")\n",
        "#         if ptype == \"page_id\":\n",
        "#             current = parent.get(\"page_id\")\n",
        "#             continue\n",
        "#         # workspace/database/unknown => stop\n",
        "#         return False\n",
        "#     return False\n",
        "\n",
        "\n",
        "# # -----------------------\n",
        "# # WEBHOOK ENDPOINT\n",
        "# # -----------------------\n",
        "# @app.post(\"/notion/webhook\")\n",
        "# async def notion_webhook(req: Request):\n",
        "#     raw = await req.body()\n",
        "#     sig = req.headers.get(\"X-Notion-Signature\")\n",
        "\n",
        "#     # Validate signature (recommended) :contentReference[oaicite:7]{index=7}\n",
        "#     verify_notion_signature(raw, sig)\n",
        "\n",
        "#     payload = json.loads(raw.decode(\"utf-8\"))\n",
        "\n",
        "#     # Subscription verification request contains verification_token :contentReference[oaicite:8]{index=8}\n",
        "#     if \"verification_token\" in payload:\n",
        "#         # You do NOT “respond with” the token. You paste it into Notion UI to verify.\n",
        "#         # Return 200 OK to confirm endpoint is reachable.\n",
        "#         return {\"ok\": True}\n",
        "\n",
        "#     # Event payloads are \"signals\": you then fetch latest data via API :contentReference[oaicite:9]{index=9}\n",
        "#     event_type = payload.get(\"type\")\n",
        "#     entity = payload.get(\"entity\", {})\n",
        "#     entity_type = entity.get(\"type\")\n",
        "#     entity_id = entity.get(\"id\")\n",
        "\n",
        "#     # We care about page content updates :contentReference[oaicite:10]{index=10}\n",
        "#     if event_type == \"page.content_updated\" and entity_type == \"page\" and entity_id:\n",
        "#         if not is_descendant_of_root(entity_id, ROOT_PAGE_ID):\n",
        "#             return {\"ok\": True, \"ignored\": \"not under root\"}\n",
        "\n",
        "#         page = retrieve_page(entity_id)\n",
        "#         topic = page_title(page)\n",
        "\n",
        "#         md_text = walk_page_as_markdown(entity_id)\n",
        "#         posts = generate_10_posts(md_text, topic)\n",
        "\n",
        "#         # Store results somewhere (example: local file). Replace with Notion write-back or Mastodon queue.\n",
        "#         out = {\n",
        "#             \"page_id\": entity_id,\n",
        "#             \"topic\": topic,\n",
        "#             \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
        "#             \"posts\": [p.model_dump() for p in posts.posts],\n",
        "#         }\n",
        "#         with open(\"notion_generated_posts.json\", \"a\", encoding=\"utf-8\") as f:\n",
        "#             f.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "#     return {\"ok\": True}"
      ],
      "metadata": {
        "id": "zVkTn0HRAPwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhisaZNH58IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Project Applications\n",
        "\n",
        "\n",
        "### 1: Replace local knowledgebase with Notion api to get docs\n",
        "\n",
        "\n",
        "### 2: Modify Chunking on your docs\n",
        "Modify `chunk_document()` to chunk by:\n",
        "- Fixed character count (e.g., 500 chars)\n",
        "- Paragraph boundaries\n",
        "- Sentence count\n",
        "\n",
        "### 4: Add RAG retrieval to create posts function context\n",
        "\n",
        "\n",
        "### 5: Auto-create posts using Notion API listener\n",
        "\n",
        "### 6: Auto-reply to comments using Mastodon comments listener\n",
        "\n",
        "### 7: OPTIONAL: Add posts to sqllite db storage for retrieval"
      ],
      "metadata": {
        "id": "ZwxvCw-56Csj"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}